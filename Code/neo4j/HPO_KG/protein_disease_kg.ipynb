{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b50f09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "from anytree import Node, RenderTree\n",
    "from collections import defaultdict\n",
    "from neo4j.exceptions import ClientError as Neo4jClientError\n",
    "import pandas\n",
    "from util.base_importer import BaseImporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbdce700",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='[%(asctime)s] %(levelname)s - %(message)s',\n",
    "    datefmt='%H:%M:%S'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42317023",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPIImporter(BaseImporter):\n",
    "\n",
    "    def __init__(self, argv=[]): # Default to empty list for notebook\n",
    "        # Replace __file__ with a string because __file__ doesn't exist in notebooks\n",
    "        super().__init__(command=\"PPIImporter_Notebook\", argv=argv) \n",
    "        self._database = \"neo4j\"\n",
    "        # do not use it since in community edition just one db(default) is enabled.\n",
    "        #with self._driver.session(database=\"system\") as session:\n",
    "        #    session.run(f\"CREATE DATABASE {self._database} IF NOT EXISTS\")\n",
    "    def set_constrainsts(self):\n",
    "        #Listing 4.1\n",
    "        # cannot use NODE KEY in community edition.\n",
    "        #queries=[\"CREATE CONSTRAINT protein_key IF NOT EXISTS FOR (n:Protein) REQUIRE (n.id) IS NODE KEY\",\n",
    "        #         \"CREATE CONSTRANT disease_key IF NOT EXISTS FOR (n:Disease) REQUIRE (n.id) IS NODE KEY\"]\n",
    "        queries= [\"CREATE CONSTRAINT protein_unique IF NOT EXISTS FOR (n:Protein) REQUIRE n.id IS UNIQUE;\",\n",
    "                  \"CREATE CONSTRAINT disease_unique IF NOT EXISTS FOR (n:Disease) REQUIRE n.id IS UNIQUE;\",\n",
    "                  \"CREATE INDEX disease_id IF NOT EXISTS FOR (n:Disease) ON (n.id);\",\n",
    "                  \"CREATE INDEX protein_id IF NOT EXISTS FOR (n:Protein) ON (n.id);\"]\n",
    "        with self._driver.session(database=self._database) as session:\n",
    "            for q in queries:\n",
    "                try:\n",
    "                    session.run(q)\n",
    "                except Neo4jClientError as e:\n",
    "                     if e.code != \"Neo.ClientError.Schema.EquivalentSchemaRuleAlreadyExists\":\n",
    "                        raise e\n",
    "\n",
    "    def load_ppi_csv(self):\n",
    "        query = \"\"\"LOAD CSV  WITH HEADERS\n",
    "        FROM 'file:///PPI/bio-pathways-network.csv' AS line\n",
    "        CALL {\n",
    "        WITH line\n",
    "            MERGE (f:Protein {id: trim(line[\"Gene ID 1\"])})\n",
    "            MERGE (s:Protein {id: trim(line[\"Gene ID 2\"])})\n",
    "            MERGE (f)-[:INTERACTS_WITH]->(s)\n",
    "        } IN TRANSACTIONS OF 100 ROWS\"\"\"\n",
    "        with self._driver.session(database=self._database) as session:\n",
    "            session.run(query)\n",
    "                \n",
    "    def protein_disease_r(self):\n",
    "        query = \"\"\"LOAD CSV WITH HEADERS \n",
    "                    FROM 'file:///PPI/bio-pathways-associations.csv' AS line\n",
    "                    CALL {\n",
    "                        WITH line\n",
    "                        WITH trim(line[\"Associated Gene IDs\"]) AS proteins,\n",
    "                    trim(line[\"Disease Name\"]) AS diseaseName,\n",
    "                    trim(line[\"Disease ID\"]) AS diseaseId\n",
    "                        MERGE (d:Disease {id: diseaseId, name: diseaseName})\n",
    "                        WITH d, proteins\n",
    "                        UNWIND split(proteins, \",\") AS protein\n",
    "                        WITH d, protein\n",
    "                        MERGE (p:Protein {id: trim(protein)})\n",
    "                        MERGE (d)-[:ASSOCIATED_WITH]->(p)\n",
    "                    } IN TRANSACTIONS OF 100 ROWS\"\"\"\n",
    "        with self._driver.session(database=self._database) as session:\n",
    "            session.run(query)\n",
    "    def disease_classes(self):\n",
    "        query=\"\"\"LOAD CSV WITH HEADERS \n",
    "                    FROM 'file:///PPI/bio-pathways-diseaseclasses.csv' AS line\n",
    "                    CALL {\n",
    "                        WITH line\n",
    "                        WITH line[\"Disease ID\"] as diseaseId, line[\"Disease Class\"] as class\n",
    "                        MATCH (d:Disease {id:diseaseId})\n",
    "                        SET d.class = class\n",
    "                    } IN TRANSACTIONS OF 100 ROWS\"\"\"\n",
    "        with self._driver.session(database=self._database) as session:\n",
    "            session.run(query)\n",
    "        \n",
    "    def gene_info(self):\n",
    "        query=\"\"\"LOAD CSV WITH HEADERS FROM 'file:///PPI/gene_info' AS line \n",
    "            FIELDTERMINATOR '\\t'\n",
    "            CALL {\n",
    "                WITH line\n",
    "                WITH trim(line[\"GeneID\"]) AS proteinId, trim(line[\"Symbol\"]) AS symbol,\n",
    "                trim(line[\"description\"]) AS description\n",
    "                WITH proteinId, symbol, description\n",
    "                MATCH (p:Protein {id:proteinId})\n",
    "                SET p.name = symbol, p.description = description\n",
    "            } IN TRANSACTIONS OF 100 ROWS\"\"\"\n",
    "        with self._driver.session(database=self._database) as session:\n",
    "            session.run(query)\n",
    "    def add_ppi_protein_label(self):\n",
    "        #filter so the algorithm doesn't waste time on \"lonely\" proteins.\n",
    "        query=\"\"\"MATCH (p:Protein)-[:INTERACTS_WITH]-()\n",
    "                 SET p:PPIProtein\"\"\"\n",
    "        with self._driver.session(database=self._database) as session:\n",
    "            session.run(query)\n",
    "    def inmemory_ppi_graph(self):\n",
    "        #take a \"snapshot\" or a specific \"subset\" of items and move them to a workbench (RAM) where we can work fast.\n",
    "        query=\"\"\" call gds.graph.project(\n",
    "        'ppi-graph',\n",
    "        'PPIProtein',\n",
    "            {INTERACTS_WITH: {\n",
    "                orientation: 'UNDIRECTED'\n",
    "            }\n",
    "        }\n",
    "        )\"\"\"\n",
    "        with self._driver.session(database=self._database) as session:\n",
    "            session.run(query)\n",
    "    def wcc(self):\n",
    "        query=\"\"\" CALL gds.wcc.write('ppi-graph', { writeProperty: 'componentId' })\n",
    "                YIELD nodePropertiesWritten, componentCount, componentDistribution;\"\"\"\n",
    "        with self._driver.session(database=self._database) as session:\n",
    "            result = session.run(query)\n",
    "            record = result.single()\n",
    "            return{\n",
    "            \"total_nodes\": record[\"nodePropertiesWritten\"],\n",
    "            \"island_count\": record[\"componentCount\"],\n",
    "            \"stats\": record[\"componentDistribution\"]}\n",
    "    def louvain(self):\n",
    "        query=\"\"\"CALL gds.louvain.write('ppi-graph', \n",
    "                { writeProperty: 'componentLouvainId' })\n",
    "                YIELD communityCount, modularity, modularities, communityDistribution\"\"\"\n",
    "        with self._driver.session(database=self._database) as session:\n",
    "                result = session.run(query)\n",
    "                record = result.single()\n",
    "                return{ \n",
    "                \"communityCount\": record[\"communityCount\"],\n",
    "                \"modularity\": record[\"modularity\"],\n",
    "                \"modularities\": record[\"modularities\"],\n",
    "\n",
    "                \"communityDistribution\": record[\"communityDistribution\"]}\n",
    "    def run_query(self, query, **params):\n",
    "            with self._driver.session(database=self._database) as session:\n",
    "                # Pass the params dictionary as the second argument to session.run()\n",
    "                result = session.run(query, params) \n",
    "                return result.to_df()\n",
    "    def analyze_hierarchy(graph_client):\n",
    "        #Fetch ALL data (Remove LIMIT 10)\n",
    "        with graph_client._driver.session() as session:\n",
    "            query = \"\"\"\n",
    "            CALL gds.louvain.stream('ppi-graph', { includeIntermediateCommunities: true })\n",
    "            YIELD nodeId, communityId, intermediateCommunityIds\n",
    "            RETURN gds.util.asNode(nodeId).name AS name, \n",
    "                intermediateCommunityIds AS levels,\n",
    "                communityId AS final\n",
    "            \"\"\"\n",
    "            results = session.run(query)\n",
    "            data = [dict(r) for r in results]\n",
    "        \n",
    "        df = pandas.DataFrame(data)\n",
    "        \n",
    "        # Summary of Levels\n",
    "        print(f\"Total Nodes Processed: {len(df)}\")\n",
    "        for i in range(len(df['levels'].iloc[0])):\n",
    "            unique_clusters = df['levels'].apply(lambda x: x[i]).nunique()\n",
    "            print(f\"Level {i}: {unique_clusters} clusters found.\")\n",
    "        print(f\"Final Level: {df['final'].nunique()} clusters found.\\n\")\n",
    "\n",
    "        nodes = {}\n",
    "        \n",
    "        def get_node(name, parent=None):\n",
    "            if name not in nodes:\n",
    "                nodes[name] = Node(name, parent=parent, count=0)\n",
    "            return nodes[name]\n",
    "\n",
    "        # Root of the whole graph\n",
    "        root = Node(\"PPI-Graph-Root\", count=len(df))\n",
    "\n",
    "        # Aggregate counts for each level\n",
    "        for _, row in df.iterrows():\n",
    "            # Path: Root -> Final -> L1 -> L0\n",
    "            final_id = f\"Final-{row['final']}\"\n",
    "            l1_id = f\"L1-{row['levels'][1]}\"\n",
    "            l0_id = f\"L0-{row['levels'][0]}\"\n",
    "            \n",
    "            f_node = get_node(final_id, parent=root)\n",
    "            f_node.count += 1\n",
    "            \n",
    "            l1_node = get_node(l1_id, parent=f_node)\n",
    "            l1_node.count += 1\n",
    "            \n",
    "            # Note: We stop here for visual clarity, \n",
    "            # but you can add Level 0 if the counts aren't too high.\n",
    "        print(\"Dendrogram of Clusters (Populations):\")\n",
    "        for pre, fill, node in RenderTree(root):\n",
    "            # Only show nodes with high populations or limit depth\n",
    "            if node.depth <= 2: \n",
    "                print(f\"{pre}{node.name} ({node.count} proteins)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f0bd8976",
   "metadata": {},
   "outputs": [],
   "source": [
    "importing = PPIImporter(argv=[])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cef0008",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08:10:26] INFO - Setting Constraints\n",
      "[08:10:26] INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT protein_unique IF NOT EXISTS FOR (e:Protein) REQUIRE (e.id) IS UNIQUE` has no effect.} {description: `CONSTRAINT protein_unique FOR (e:Protein) REQUIRE (e.id) IS UNIQUE` already exists.} {position: None} for query: 'CREATE CONSTRAINT protein_unique IF NOT EXISTS FOR (n:Protein) REQUIRE n.id IS UNIQUE;'\n",
      "[08:10:26] INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT disease_unique IF NOT EXISTS FOR (e:Disease) REQUIRE (e.id) IS UNIQUE` has no effect.} {description: `CONSTRAINT disease_unique FOR (e:Disease) REQUIRE (e.id) IS UNIQUE` already exists.} {position: None} for query: 'CREATE CONSTRAINT disease_unique IF NOT EXISTS FOR (n:Disease) REQUIRE n.id IS UNIQUE;'\n",
      "[08:10:26] INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE RANGE INDEX disease_id IF NOT EXISTS FOR (e:Disease) ON (e.id)` has no effect.} {description: `RANGE INDEX disease_unique FOR (e:Disease) ON (e.id)` already exists.} {position: None} for query: 'CREATE INDEX disease_id IF NOT EXISTS FOR (n:Disease) ON (n.id);'\n",
      "[08:10:26] INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE RANGE INDEX protein_id IF NOT EXISTS FOR (e:Protein) ON (e.id)` has no effect.} {description: `RANGE INDEX protein_unique FOR (e:Protein) ON (e.id)` already exists.} {position: None} for query: 'CREATE INDEX protein_id IF NOT EXISTS FOR (n:Protein) ON (n.id);'\n"
     ]
    }
   ],
   "source": [
    "logging.info('Setting Constraints')\n",
    "importing.set_constrainsts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c7ddba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[09:54:16] INFO - Loading PPI\n",
      "[09:54:46] WARNING - Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (line) { ... }} {position: line: 3, column: 9, offset: 91} for query: 'LOAD CSV  WITH HEADERS\\n        FROM \\'file:///PPI/bio-pathways-network.csv\\' AS line\\n        CALL {\\n        WITH line\\n            MERGE (f:Protein {id: trim(line[\"Gene ID 1\"])})\\n            MERGE (s:Protein {id: trim(line[\"Gene ID 2\"])})\\n            MERGE (f)-[:INTERACTS_WITH]->(s)\\n        } IN TRANSACTIONS OF 100 ROWS'\n"
     ]
    }
   ],
   "source": [
    "logging.info('Loading PPI')\n",
    "importing.load_ppi_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9f4928a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08:10:33] INFO - building protein-disease relationships\n",
      "[08:10:36] WARNING - Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (line) { ... }} {position: line: 3, column: 21, offset: 120} for query: 'LOAD CSV WITH HEADERS \\n                    FROM \\'file:///PPI/bio-pathways-associations.csv\\' AS line\\n                    CALL {\\n                        WITH line\\n                        WITH trim(line[\"Associated Gene IDs\"]) AS proteins,\\n                    trim(line[\"Disease Name\"]) AS diseaseName,\\n                    trim(line[\"Disease ID\"]) AS diseaseId\\n                        MERGE (d:Disease {id: diseaseId, name: diseaseName})\\n                        WITH d, proteins\\n                        UNWIND split(proteins, \",\") AS protein\\n                        WITH d, protein\\n                        MERGE (p:Protein {id: trim(protein)})\\n                        MERGE (d)-[:ASSOCIATED_WITH]->(p)\\n                    } IN TRANSACTIONS OF 100 ROWS'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'MATCH (p1:Protein)-[:ASSOCIATED_WITH]-(d:Disease)\\nWHERE NOT (p1)-[:INTERACTS_WITH]-(:Protein)\\nRETURN count(p1), p1'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logging.info('building protein-disease relationships')\n",
    "importing.protein_disease_r()\n",
    "# new proteins are obtained from the new data source.\n",
    "# we can check them with:\n",
    "\"\"\"MATCH (p1:Protein)-[:ASSOCIATED_WITH]-(d:Disease)\n",
    "WHERE NOT (p1)-[:INTERACTS_WITH]-(:Protein)\n",
    "RETURN count(p1), p1\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55373cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[09:54:59] INFO - disease classes\n",
      "[09:54:59] WARNING - Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (line) { ... }} {position: line: 3, column: 21, offset: 122} for query: 'LOAD CSV WITH HEADERS \\n                    FROM \\'file:///PPI/bio-pathways-diseaseclasses.csv\\' AS line\\n                    CALL {\\n                        WITH line\\n                        WITH line[\"Disease ID\"] as diseaseId, line[\"Disease Class\"] as class\\n                        MATCH (d:Disease {id:diseaseId})\\n                        SET d.class = class\\n                    } IN TRANSACTIONS OF 100 ROWS'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nMATCH (p:Disease)\\nWHERE p.class IS NOT NULL\\nRETURN COUNT(DISTINCT p.class), collect(DISTINCT p.class)'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logging.info('disease classes')\n",
    "importing.disease_classes()\n",
    "# 219 nodes do not have class\n",
    "# to check class names  and how many of them \n",
    "\"\"\"\n",
    "MATCH (p:Disease)\n",
    "WHERE p.class IS NOT NULL\n",
    "RETURN COUNT(DISTINCT p.class), collect(DISTINCT p.class)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22cb4299",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[09:55:02] INFO - add name and symbols to proteins\n",
      "[10:12:06] WARNING - Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (line) { ... }} {position: line: 3, column: 13, offset: 104} for query: 'LOAD CSV WITH HEADERS FROM \\'file:///PPI/gene_info\\' AS line \\n            FIELDTERMINATOR \\'\\t\\'\\n            CALL {\\n                WITH line\\n                WITH trim(line[\"GeneID\"]) AS proteinId, trim(line[\"Symbol\"]) AS symbol,\\n                trim(line[\"description\"]) AS description\\n                WITH proteinId, symbol, description\\n                MATCH (p:Protein {id:proteinId})\\n                SET p.name = symbol, p.description = description\\n            } IN TRANSACTIONS OF 100 ROWS'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'MATCH  (n: Protein)\\nwhere n.name is null\\nreturn count(n)'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logging.info('add name and symbols to proteins')\n",
    "importing.gene_info()\n",
    "# With this query check the any  remaining one that does not have name or description (231 nodes do not have them)\n",
    "\"\"\"MATCH  (n: Protein)\n",
    "where n.name is null\n",
    "return count(n)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46b6a21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[10:25:33] INFO - add  PPI protein label\n"
     ]
    }
   ],
   "source": [
    "logging.info('add  PPI protein label')\n",
    "importing.add_ppi_protein_label()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7d4ce34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08:10:45] INFO - take the PPI ones into memory\n"
     ]
    }
   ],
   "source": [
    "logging.info('take the PPI ones into memory')\n",
    "importing.inmemory_ppi_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e825eba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08:12:14] INFO - execute WCC\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'total_nodes': 21557, 'island_count': 26, 'stats': {'p1': 1, 'max': 21521, 'p5': 1, 'p90': 3, 'p50': 1, 'p95': 4, 'p10': 1, 'p75': 2, 'p99': 21521, 'p25': 1, 'min': 1, 'mean': 829.1153846153846, 'p999': 21521}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' from the numbers:\\n  we have 26 subgraphs. From 21557 nodes, 21521 nodes are connected to each other.\\n  99.8% of the nodes are in one single giant cluster.\\n  p95: 4 , %95 of our islands have 4 or less nodes, we have totally  36 (21557-21521) nodes for 25 graphs\\n  so it is reasonable to have less than 4 node for those 25 subgraphs.\\n  p999: 99.9\\n\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logging.info('execute WCC')\n",
    "response =importing.wcc()\n",
    "print(response)\n",
    "# find the sets of nodes where every node is reachable from any other node in the same set,\n",
    "#  regardless of the direction of the relationships, it is \"\"finding \"islands\" in the data\"\"\n",
    "\"\"\" from the numbers:\n",
    "  we have 26 subgraphs. From 21557 nodes, 21521 nodes are connected to each other.\n",
    "  99.8% of the nodes are in one single giant cluster.\n",
    "  p95: 4 , %95 of our islands have 4 or less nodes, we have totally  36 (21557-21521) nodes for 25 graphs\n",
    "  so it is reasonable to have less than 4 node for those 25 subgraphs.\n",
    "  p999: 99.9\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3f025d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08:12:53] INFO - execute Louvain\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'communityCount': 49,\n",
       " 'modularity': 0.4003401858047506,\n",
       " 'modularities': [0.38253603517153106, 0.4003401858047506],\n",
       " 'communityDistribution': {'p1': 1,\n",
       "  'max': 3343,\n",
       "  'p5': 1,\n",
       "  'p90': 2967,\n",
       "  'p50': 3,\n",
       "  'p95': 3249,\n",
       "  'p10': 1,\n",
       "  'p75': 112,\n",
       "  'p99': 3343,\n",
       "  'p25': 1,\n",
       "  'min': 1,\n",
       "  'mean': 439.9387755102041,\n",
       "  'p999': 3343}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logging.info('execute Louvain')\n",
    "importing.louvain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de847cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Nodes Processed: 21557\n",
      "Level 0: 460 clusters found.\n",
      "Level 1: 49 clusters found.\n",
      "Final Level: 49 clusters found.\n",
      "\n",
      "Dendrogram of Clusters (Populations):\n",
      "PPI-Graph-Root (21557 proteins)\n",
      "├── Final-15716 (2773 proteins)\n",
      "│   └── L1-15716 (2773 proteins)\n",
      "├── Final-8617 (150 proteins)\n",
      "│   └── L1-8617 (150 proteins)\n",
      "├── Final-15251 (1524 proteins)\n",
      "│   └── L1-15251 (1524 proteins)\n",
      "├── Final-15588 (3404 proteins)\n",
      "│   └── L1-15588 (3404 proteins)\n",
      "├── Final-16101 (57 proteins)\n",
      "│   └── L1-16101 (57 proteins)\n",
      "├── Final-1562 (2932 proteins)\n",
      "│   └── L1-1562 (2932 proteins)\n",
      "├── Final-11019 (2561 proteins)\n",
      "│   └── L1-11019 (2561 proteins)\n",
      "├── Final-344 (2954 proteins)\n",
      "│   └── L1-344 (2954 proteins)\n",
      "├── Final-13634 (2234 proteins)\n",
      "│   └── L1-13634 (2234 proteins)\n",
      "├── Final-433 (395 proteins)\n",
      "│   └── L1-433 (395 proteins)\n",
      "├── Final-6639 (1098 proteins)\n",
      "│   └── L1-6639 (1098 proteins)\n",
      "├── Final-487 (594 proteins)\n",
      "│   └── L1-487 (594 proteins)\n",
      "├── Final-11604 (171 proteins)\n",
      "│   └── L1-11604 (171 proteins)\n",
      "├── Final-16030 (229 proteins)\n",
      "│   └── L1-16030 (229 proteins)\n",
      "├── Final-16033 (72 proteins)\n",
      "│   └── L1-16033 (72 proteins)\n",
      "├── Final-2504 (253 proteins)\n",
      "│   └── L1-2504 (253 proteins)\n",
      "├── Final-2300 (48 proteins)\n",
      "│   └── L1-2300 (48 proteins)\n",
      "├── Final-2520 (19 proteins)\n",
      "│   └── L1-2520 (19 proteins)\n",
      "├── Final-8749 (19 proteins)\n",
      "│   └── L1-8749 (19 proteins)\n",
      "├── Final-5854 (5 proteins)\n",
      "│   └── L1-5854 (5 proteins)\n",
      "├── Final-17381 (8 proteins)\n",
      "│   └── L1-17381 (8 proteins)\n",
      "├── Final-2928 (9 proteins)\n",
      "│   └── L1-2928 (9 proteins)\n",
      "├── Final-8818 (8 proteins)\n",
      "│   └── L1-8818 (8 proteins)\n",
      "├── Final-18902 (4 proteins)\n",
      "│   └── L1-18902 (4 proteins)\n",
      "├── Final-16743 (4 proteins)\n",
      "│   └── L1-16743 (4 proteins)\n",
      "├── Final-12511 (2 proteins)\n",
      "│   └── L1-12511 (2 proteins)\n",
      "├── Final-15863 (3 proteins)\n",
      "│   └── L1-15863 (3 proteins)\n",
      "├── Final-11827 (3 proteins)\n",
      "│   └── L1-11827 (3 proteins)\n",
      "├── Final-13932 (1 proteins)\n",
      "│   └── L1-13932 (1 proteins)\n",
      "├── Final-14881 (1 proteins)\n",
      "│   └── L1-14881 (1 proteins)\n",
      "├── Final-15373 (1 proteins)\n",
      "│   └── L1-15373 (1 proteins)\n",
      "├── Final-17096 (1 proteins)\n",
      "│   └── L1-17096 (1 proteins)\n",
      "├── Final-17194 (1 proteins)\n",
      "│   └── L1-17194 (1 proteins)\n",
      "├── Final-17283 (1 proteins)\n",
      "│   └── L1-17283 (1 proteins)\n",
      "├── Final-17360 (3 proteins)\n",
      "│   └── L1-17360 (3 proteins)\n",
      "├── Final-17732 (1 proteins)\n",
      "│   └── L1-17732 (1 proteins)\n",
      "├── Final-18466 (1 proteins)\n",
      "│   └── L1-18466 (1 proteins)\n",
      "├── Final-18925 (1 proteins)\n",
      "│   └── L1-18925 (1 proteins)\n",
      "├── Final-19093 (2 proteins)\n",
      "│   └── L1-19093 (2 proteins)\n",
      "├── Final-19097 (1 proteins)\n",
      "│   └── L1-19097 (1 proteins)\n",
      "├── Final-19122 (1 proteins)\n",
      "│   └── L1-19122 (1 proteins)\n",
      "├── Final-19510 (1 proteins)\n",
      "│   └── L1-19510 (1 proteins)\n",
      "├── Final-19757 (1 proteins)\n",
      "│   └── L1-19757 (1 proteins)\n",
      "├── Final-20302 (1 proteins)\n",
      "│   └── L1-20302 (1 proteins)\n",
      "├── Final-20957 (1 proteins)\n",
      "│   └── L1-20957 (1 proteins)\n",
      "├── Final-20989 (1 proteins)\n",
      "│   └── L1-20989 (1 proteins)\n",
      "├── Final-21325 (1 proteins)\n",
      "│   └── L1-21325 (1 proteins)\n",
      "├── Final-21409 (1 proteins)\n",
      "│   └── L1-21409 (1 proteins)\n",
      "└── Final-21520 (1 proteins)\n",
      "    └── L1-21520 (1 proteins)\n"
     ]
    }
   ],
   "source": [
    "importing.analyze_hierarchy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ef44735",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08:14:58] INFO - examine communities\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " communityId  members keyMembers                                                                                                                                        \n",
      "  232        2967                        APP, GRB2, EGFR, SRC, PRKACA, FYN, PRKCA, ABL1, CRK, NEDD4, ARRB1, PIK3R1, CDC42, SH3KBP1, STAT3, PLCG1, SHC1, CBL, ADRB2, Dlg4\n",
      "13634        3249                    NTRK1, UBC, HSP90AA1, VCP, HSPA8, TRAF6, HSPA5, BAG3, VHL, IKBKG, HSPB1, PRKN, IKBKE, HSPA4, HSPA1A, HLA-B, TERF1, MCC, BAG6, PSMA3\n",
      "11792        3282       ELAVL1, MOV10, NXF1, FBXO6, SHMT2, TMEM17, TCTN3, CREB3, TMEM216, VAPA, TCTN2, CANX, UQCRC2, FAF2, LGALS3, RAB7A, GOLT1B, STX1A, APPBP2, CREB3L1\n",
      "15714        2276                  XPO1, YWHAZ, YWHAG, ACTB, YWHAQ, PPP1CA, YWHAE, FBXW11, YWHAB, MED4, FLNA, CLTC, BTRC, MYH9, YWHAH, PPP1CC, APC, PPP2R1A, DYNLL1, SFN\n",
      " 5500        1421               CUL3, MCM2, COPS5, FN1, CUL1, RNF2, NPM1, HNRNPA1, CAND1, HNRNPU, SIRT7, CUL7, OBSL1, EEF1A1, CCDC8, HSP90AB1, DHX9, ITGA4, CUL2, PABPC1\n",
      " 2520        3343                        TP53, CDK2, ESR1, EWSR1, CSNK2A1, HDAC1, BRCA1, MYC, EP300, UBE2I, RPA1, RPA2, MDM2, SP1, RELA, SMAD3, CDK1, JUN, MAPK1, CREBBP\n",
      "12385        3032     MEOX2, CYSRT1, TRAF2, LNX1, KRTAP10-3, TRIM27, GOLGA2, MDFI, PICK1, KRTAP10-8, REL, KRT40, KRT31, NOTCH2NLA, PROP1, MTUS2, HGS, SDCBP, WWOX, CDC37\n",
      "  330         411     CALM1, SNCA, CFTR, MKRN1, HACE1, ADORA2A, SLC6A2, CLDN7, EPCAM, SH3BGRL2, Tcp1, Hspa5, Sptan1, Rab8a, SLC4A8, Fhl1, Hsp90ab1, Lin28a, Ap1b1, NRIP3\n",
      "  195         564      SF3B3, SRPK2, EIF4A3, DDX5, SF3B1, DHX15, TFIP11, DDX3X, SNRNP200, SF3B2, U2AF2, HNRNPK, U2AF1, SNU13, SUZ12, SRRM2, CDC5L, SNRPB, PRPF40A, SRSF1\n",
      " 2504         253           STXBP5L, PRICKLE1, PRICKLE2, Tubb4b, Mycbp2, Tubb5, Rps26, Tanc1, Dnaja2, Usp9x, Rpl4, Nucb1, Bcr, Gnb1, Cad, Clta, Rpl23, Psmc5, Tanc2, Gsn\n"
     ]
    }
   ],
   "source": [
    "examine_communities= \"\"\"MATCH (p:PPIProtein)\n",
    "                        WITH p.componentLouvainId as communityId, count(p) as members\n",
    "                        ORDER BY members desc\n",
    "                        LIMIT 10\n",
    "                        MATCH (p:PPIProtein)-[:INTERACTS_WITH]-(o)\n",
    "                        WHERE p.componentLouvainId = communityId\n",
    "                        WITH communityId, members, p.name as name, count(o) as connections\n",
    "                        ORDER BY connections DESC\n",
    "                        RETURN communityId, members, collect(name)[..20] as keyMembers\"\"\"\n",
    "logging.info('examine communities')\n",
    "#This query shows the top 20 most connected elements for each community identified by Louvain\n",
    "df = importing.run_query(examine_communities)\n",
    "df['keyMembers'] = df['keyMembers'].apply(lambda x: \", \".join(x) if isinstance(x, list) else x)\n",
    "\n",
    "#A table showing the community ID, how many proteins it has, and a list of its 20 most connected proteins.\n",
    "print(df.head(10).to_string(index=False, justify='left'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "397e4802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     m0     r  \\\n",
      "0     (componentId, componentLouvainId, name, descri...  None   \n",
      "1     (componentId, componentLouvainId, name, descri...  None   \n",
      "2     (componentId, componentLouvainId, name, descri...  None   \n",
      "3     (componentId, componentLouvainId, name, descri...  None   \n",
      "4     (componentId, componentLouvainId, name, descri...  None   \n",
      "...                                                 ...   ...   \n",
      "2020  (componentId, componentLouvainId, name, descri...  None   \n",
      "2021  (componentId, componentLouvainId, name, descri...  None   \n",
      "2022  (componentId, componentLouvainId, name, descri...  None   \n",
      "2023  (componentId, componentLouvainId, name, descri...  None   \n",
      "2024  (componentId, componentLouvainId, name, descri...  None   \n",
      "\n",
      "                                                     m1  \n",
      "0     (componentId, componentLouvainId, name, descri...  \n",
      "1     (componentId, componentLouvainId, name, descri...  \n",
      "2     (componentId, componentLouvainId, name, descri...  \n",
      "3     (componentId, componentLouvainId, name, descri...  \n",
      "4     (componentId, componentLouvainId, name, descri...  \n",
      "...                                                 ...  \n",
      "2020  (componentId, componentLouvainId, name, descri...  \n",
      "2021                            (name, description, id)  \n",
      "2022  (componentId, componentLouvainId, name, descri...  \n",
      "2023  (componentId, componentLouvainId, name, descri...  \n",
      "2024  (componentId, componentLouvainId, name, descri...  \n",
      "\n",
      "[2025 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "disease_id=\"C0036095\"\n",
    "# pathway analysis\n",
    "query= \"\"\"MATCH (d:Disease {id:$id})- [ASSOCIATED_WITH]->(p)\n",
    "        WITH collect(p) as proteins\n",
    "        UNWIND proteins as m0\n",
    "        UNWIND proteins as m1\n",
    "        OPTIONAL MATCH (m0)-[r:INTERACTS_WITH]->(m1)\n",
    "        RETURN DISTINCT m0,r,m1\n",
    "\n",
    "\"\"\"\n",
    "df = importing.run_query(query, id=disease_id)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c0337383",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from util.graphdb_base import GraphDBBase\n",
    "\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import sys\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from util.networkx_utility import graph_undirected_from_cypher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ffd21ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MultiOmicAnalysis(GraphDBBase):\n",
    "    def __init__(self, argv, database):\n",
    "        super().__init__(command=__file__, argv=argv)\n",
    "        self.__database = database\n",
    "\n",
    "    def get_raw_data(self, query, param):\n",
    "        \"\"\"Fetches the graph structure directly from Neo4j.\"\"\"\n",
    "        with self._driver.session(database=self.__database) as session:\n",
    "            results = session.run(query, param)\n",
    "            return results.graph()\n",
    "\n",
    "    def load_hd(self, disease):\n",
    "        \"\"\"\n",
    "        Retrieves the disease subnetwork (Hd). \n",
    "        Uses the OPTIONAL MATCH to find interactions within the protein set.\n",
    "        \"\"\"\n",
    "        query = \"\"\"\n",
    "            MATCH (d:Disease {id:$id})-[:ASSOCIATED_WITH]->(p)\n",
    "            WITH collect(p) as proteins\n",
    "            UNWIND proteins as m0\n",
    "            UNWIND proteins as m1\n",
    "            OPTIONAL MATCH (m0)-[r:INTERACTS_WITH]->(m1)\n",
    "            return distinct m0, r, m1\n",
    "        \"\"\"\n",
    "        param = {\"id\": disease}\n",
    "        return self.load_graph_and_get_nx_graph(query, param)\n",
    "\n",
    "    def load_graph_and_get_nx_graph(self, query, param={}):\n",
    "        \"\"\"Converts Neo4j graph data into a NetworkX undirected graph.\"\"\"\n",
    "        data = self.get_raw_data(query, param)\n",
    "        G = graph_undirected_from_cypher(data)\n",
    "        return G\n",
    "\n",
    "    def compute_largest_components(self, networkx_graph):\n",
    "        \"\"\"Finds the nodes belonging to the largest connected cluster.\"\"\"\n",
    "        if not networkx_graph.nodes:\n",
    "            return set()\n",
    "        largest_cc = max(nx.connected_components(networkx_graph), key=len)\n",
    "        return largest_cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01ec253",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_neo4j",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
