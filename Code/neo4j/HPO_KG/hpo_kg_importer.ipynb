{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bda39ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "\n",
    "from neo4j.exceptions import ClientError as Neo4jClientError\n",
    "\n",
    "from util.base_importer import BaseImporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7509efcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='[%(asctime)s] %(levelname)s - %(message)s',\n",
    "    datefmt='%H:%M:%S'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfdd41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class HPOImporter(BaseImporter):\n",
    "\n",
    "    def __init__(self, argv=[]): # Default to empty list for notebook\n",
    "        # Replace __file__ with a string because __file__ doesn't exist in notebooks\n",
    "        super().__init__(command=\"HPOImporter_Notebook\", argv=argv) \n",
    "        self._database = \"neo4j\"\n",
    "        # do not use it since in community edition just one db(default) is enabled.\n",
    "        #with self._driver.session(database=\"system\") as session:\n",
    "            #Listing 3.13\n",
    "        #    session.run(f\"CREATE DATABASE {self._database} IF NOT EXISTS\")\n",
    "\n",
    "    def set_constraints(self):\n",
    "        # Listing 14\n",
    "        queries = [\"CREATE CONSTRAINT n10s_unique_uri IF NOT EXISTS FOR (r:Resource) REQUIRE r.uri IS UNIQUE;\",\n",
    "                   \"CREATE CONSTRAINT IF NOT EXISTS FOR (n:Resource) REQUIRE (n.id) IS UNIQUE;\",\n",
    "                   \"CREATE INDEX disease_id IF NOT EXISTS FOR (n:HpoDisease) ON (n.id);\",\n",
    "                   \"CREATE INDEX phenotype_id IF NOT EXISTS FOR (n:HpoPhenotype) ON (n.id);\"]\n",
    "        with self._driver.session(database=self._database) as session:\n",
    "            for q in queries:\n",
    "                try:\n",
    "                    session.run(q)\n",
    "                except Neo4jClientError as e:\n",
    "                    # ignore if we already have the rule in place\n",
    "                    if e.code != \"Neo.ClientError.Schema.EquivalentSchemaRuleAlreadyExists\":\n",
    "                        raise e\n",
    "\n",
    "    def check_neo_semantics(self):\n",
    "        query = 'SHOW PROCEDURES YIELD name WHERE name =\"n10s.graphconfig.init\"'\n",
    "        with self._driver.session(database=self._database) as session:\n",
    "            r = session.run(query)\n",
    "            if len(r.data()) == 0:\n",
    "                raise RuntimeError(\n",
    "                    \"Can not find `n10s.graphconfig.init`.Please make sure that Neosemantics is installed.\\n\"\n",
    "                    \"https://neo4j.com/labs/neosemantics/installation/\")\n",
    "\n",
    "    def initialize_neo_semantics(self):\n",
    "        # check if the RDF data is already imported\n",
    "        test_query = \"MATCH (n:Resource) RETURN n\"\n",
    "        with self._driver.session(database=self._database) as session:\n",
    "            r = session.run(test_query)\n",
    "            if len(r.data()) == 0:\n",
    "                # Listing 15\n",
    "                queries = [\"CALL n10s.graphconfig.init();\",\n",
    "                           \"CALL n10s.graphconfig.set({ handleVocabUris: 'IGNORE' });\", # to ignore namespaces, e.g. http://xmlns.com/foaf/0.1/name, take this as name\n",
    "                           \"CALL n10s.graphconfig.set({ applyNeo4jNaming: True });\"] # to encode relationships with Uppercase\n",
    "\n",
    "                with self._driver.session(database=self._database) as session:\n",
    "                    for q in queries:\n",
    "                        session.run(q)\n",
    "                       \n",
    "\n",
    "    def load_HPO_ontology(self):\n",
    "        # Listing 16\n",
    "        query = \"\"\"\n",
    "                CALL n10s.rdf.import.fetch(\"http://purl.obolibrary.org/obo/hp.owl\",\"RDF/XML\");\n",
    "                \"\"\"\n",
    "        with self._driver.session(database=self._database) as session:\n",
    "            session.run(query)\n",
    "\n",
    "    def label_HPO_entities(self):\n",
    "        # Listing 17\n",
    "        #put the HpoPhenotype label for HP ones, and put id to null ones.\n",
    "        query = \"\"\"\n",
    "                MATCH (n:Resource) \n",
    "                WHERE n.uri STARTS WITH \"http://purl.obolibrary.org/obo/HP\" \n",
    "                SET n:HpoPhenotype, \n",
    "                    n.id = coalesce(n.id, replace(apoc.text.replace(n.uri,'(.*)obo/',''),'_', ':'));\n",
    "                \"\"\"\n",
    "        with self._driver.session(database=self._database) as session:\n",
    "            session.run(query)\n",
    "\n",
    "    def create_disease_entities(self):\n",
    "        # Listing 19\n",
    "        query = \"\"\"\n",
    "                LOAD CSV FROM 'https://github.com/obophenotype/human-phenotype-ontology/releases/latest/download/phenotype.hpoa' AS row \n",
    "                FIELDTERMINATOR '\\t'\n",
    "                WITH row\n",
    "                SKIP 5 \n",
    "                MERGE (dis:Resource:HpoDisease {id: row[0]}) \n",
    "                ON CREATE SET dis.label = row[1]; \n",
    "                \"\"\"\n",
    "\n",
    "        with self._driver.session(database=self._database) as session:\n",
    "            session.run(query)\n",
    "\n",
    "    def create_rels_features_diseases(self):\n",
    "        # Listing 20\n",
    "        query = \"\"\"\n",
    "                LOAD CSV FROM 'https://github.com/obophenotype/human-phenotype-ontology/releases/latest/download/phenotype.hpoa' AS row\n",
    "                FIELDTERMINATOR '\\t'\n",
    "                WITH row\n",
    "                SKIP 5\n",
    "                MATCH (dis:HpoDisease)\n",
    "                WHERE dis.id = row[0]\n",
    "                MATCH (phe:HpoPhenotype)\n",
    "                WHERE phe.id = row[3]\n",
    "                MERGE (dis)-[:HAS_PHENOTYPIC_FEATURE]->(phe)\n",
    "                \"\"\"\n",
    "\n",
    "        with self._driver.session(database=self._database) as session:\n",
    "            session.run(query)\n",
    "\n",
    "    def add_base_properties_to_rels(self):\n",
    "        # Listing 22\n",
    "        # take the different properties from the columns\n",
    "        # for each iterate over the list comes from the case statement, if the specific column is empty,\n",
    "        # it returns empty list and set statement is not executed, if the row is not empty, it returns a list with one dummy variable\n",
    "        # and query is execute one for that specific row.\n",
    "        query = \"\"\"\n",
    "                LOAD CSV FROM 'https://github.com/obophenotype/human-phenotype-ontology/releases/latest/download/phenotype.hpoa' AS row \n",
    "                FIELDTERMINATOR '\\t' \n",
    "                WITH row \n",
    "                SKIP 5 \n",
    "                MATCH (dis:HpoDisease)-[rel:HAS_PHENOTYPIC_FEATURE]->(phe:HpoPhenotype)\n",
    "                WHERE phe.id = row[3] and dis.id = row[0] \n",
    "                FOREACH(ignoreMe IN CASE WHEN row[4] is not null THEN [1] ELSE [] END| \n",
    "                    SET rel.source = row[4]) \n",
    "                FOREACH(ignoreMe IN CASE WHEN row[5] is not null THEN [1] ELSE [] END| \n",
    "                    SET rel.evidence = row[5]) \n",
    "                FOREACH(ignoreMe IN CASE WHEN row[6] is not null THEN [1] ELSE [] END| \n",
    "                    SET rel.onset = row[6]) \n",
    "                FOREACH(ignoreMe IN CASE WHEN row[7] is not null THEN [1] ELSE [] END| \n",
    "                    SET rel.frequency = row[7]) \n",
    "                FOREACH(ignoreMe IN CASE WHEN row[8] is not null THEN [1] ELSE [] END| \n",
    "                    SET rel.sex = row[8]) \n",
    "                FOREACH(ignoreMe IN CASE WHEN row[9] is not null THEN [1] ELSE [] END| \n",
    "                    SET rel.modifier = row[9]) \n",
    "                FOREACH(ignoreMe IN CASE WHEN row[10] is not null THEN [1] ELSE [] END| \n",
    "                    SET rel.aspect = row[10])\n",
    "                FOREACH(ignoreMe IN CASE WHEN row[11] is not null THEN [1] ELSE [] END| \n",
    "                    SET rel.biocuration = row[11])\n",
    "                \"\"\"\n",
    "\n",
    "        with self._driver.session(database=self._database) as session:\n",
    "            session.run(query)\n",
    "\n",
    "    def enrich_with_descriptive_properties(self):\n",
    "        # Listing 23\n",
    "        #split \tbicuration HPO:probinson[2021-06-21] to creadtion date and created by\n",
    "        #give name of the aspect from aspect code P or I, put aspect description\n",
    "        #give name of the evidence from evidence code IEA, PCS, or TAS, put evidence description\n",
    "        # create clickable url for source\n",
    "        query = \"\"\"\n",
    "                CALL apoc.periodic.iterate(\n",
    "                    \"MATCH (dis:HpoDisease)-[rel:HAS_PHENOTYPIC_FEATURE]->(phe:HpoPhenotype) RETURN rel\",\n",
    "                    \"SET rel.createdBy = apoc.text.regexGroups(rel.biocuration, 'HPO:(\\\\w+)\\\\[')[0][1],\n",
    "                    rel.creationDate = apoc.text.regexGroups(rel.biocuration, '\\\\[(\\\\d{4}-\\\\d{2}-\\\\d{2})\\\\]')[0][1],\n",
    "                    rel.aspectName = \n",
    "                    CASE  \n",
    "                        WHEN rel.aspect = 'P' THEN 'Phenotypic abnormality' \n",
    "                        WHEN rel.aspect = 'I' THEN 'Inheritance' \n",
    "                    END, \n",
    "                    rel.aspectDescription = \n",
    "                    CASE \n",
    "                        WHEN rel.aspect = 'P' THEN 'Terms with the P aspect are located in the Phenotypic abnormality subontology' \n",
    "                        WHEN rel.aspect = 'I' THEN 'Terms with the I aspect are from the Inheritance subontology' \n",
    "                    END, \n",
    "                    rel.evidenceName = \n",
    "                    CASE  \n",
    "                        WHEN rel.evidence = 'IEA' THEN 'Inferred from electronic annotation' \n",
    "                        WHEN rel.evidence = 'PCS' THEN 'Published clinical study' \n",
    "                        WHEN rel.evidence = 'TAS' THEN 'Traceable author statement' \n",
    "                    END, \n",
    "                    rel.evidenceDescription = \n",
    "                    CASE \n",
    "                        WHEN rel.evidence = 'IEA' THEN 'Annotations extracted by parsing the Clinical Features sections of the Online Mendelian Inheritance in Man resource are assigned the evidence code IEA.' \n",
    "                        WHEN rel.evidence = 'PCS' THEN 'PCS is used for information extracted from articles in the medical literature. Generally, annotations of this type will include the pubmed id of the published study in the DB_Reference field.' \n",
    "                        WHEN rel.evidence = 'TAS' THEN 'TAS is used for information gleaned from knowledge bases such as OMIM or Orphanet that have derived the information from a published source.' \n",
    "                    END, \n",
    "                    rel.url = \n",
    "                    CASE \n",
    "                        WHEN rel.source STARTS WITH 'PMID:' THEN 'https://pubmed.ncbi.nlm.nih.gov/' + apoc.text.replace(rel.source, '(.*)PMID:', '') \n",
    "                        WHEN rel.source STARTS WITH 'OMIM:' THEN 'https://omim.org/entry/' + apoc.text.replace(rel.source, '(.*)OMIM:', '') \n",
    "                    END\",\n",
    "                {batchSize: 1000})\n",
    "                \"\"\"\n",
    "\n",
    "        with self._driver.session(database=self._database) as session:\n",
    "            session.run(query)\n",
    "    \n",
    "    def remove_unused_node(self):\n",
    "        # Listing 27\n",
    "        query = \"\"\"\n",
    "                CALL apoc.periodic.iterate(\n",
    "                    \"MATCH (n:Resource) RETURN id(n) as node_id\",\n",
    "                    \"MATCH (n)\n",
    "                     WHERE id(n) = node_id AND\n",
    "                           NOT 'HpoPhenotype' in labels(n) AND\n",
    "                           NOT 'HpoDisease' in labels(n)\n",
    "                     DETACH DELETE n\",\n",
    "                     {batchSize:10000})\n",
    "                YIELD batches, total return batches, total\n",
    "                \"\"\"\n",
    "\n",
    "        with self._driver.session(database=self._database) as session:\n",
    "            session.run(query)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d37bbcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "importing = HPOImporter(argv=[])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ce69a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08:18:20] INFO - Setting Constraints\n"
     ]
    }
   ],
   "source": [
    "logging.info('Setting Constraints')\n",
    "importing.set_constraints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e4f739c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08:29:43] INFO - Initializing Neosemantics\n"
     ]
    }
   ],
   "source": [
    "logging.info('Initializing Neosemantics')\n",
    "importing.check_neo_semantics()\n",
    "importing.initialize_neo_semantics()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31f57917",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08:34:09] INFO - Loading HPO Ontology\n"
     ]
    }
   ],
   "source": [
    "logging.info('Loading HPO Ontology')\n",
    "importing.load_HPO_ontology()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43825019",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08:46:33] INFO - Loading HPO Entities\n"
     ]
    }
   ],
   "source": [
    "logging.info('Loading HPO Entities')\n",
    "importing.label_HPO_entities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1af994c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08:54:34] INFO - Creating Disease Entities\n"
     ]
    }
   ],
   "source": [
    "logging.info('Creating Disease Entities')\n",
    "importing.create_disease_entities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0336a451",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[09:06:41] INFO - Creating Phenotype Relationships\n"
     ]
    }
   ],
   "source": [
    "logging.info('Creating Phenotype Relationships')\n",
    "importing.create_rels_features_diseases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67caecf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[09:28:36] INFO - Base Relationship Enriching\n"
     ]
    }
   ],
   "source": [
    "logging.info('Base Relationship Enriching')\n",
    "importing.add_base_properties_to_rels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6bcb1865",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[09:41:03] INFO - Descriptive Relationship Enriching\n"
     ]
    }
   ],
   "source": [
    "logging.info('Descriptive Relationship Enriching')\n",
    "importing.enrich_with_descriptive_properties()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df26fcf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[09:44:31] INFO - Cleaning the Knowledge Graph...\n"
     ]
    }
   ],
   "source": [
    "logging.info('Cleaning the Knowledge Graph...')\n",
    "importing.remove_unused_node()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4966cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## the end graph can be checked with these queries e.g. from http://localhost:7474/browser/\n",
    "# to see the diseases for the symptoms of a person\n",
    "\"\"\"MATCH (phe:HpoPhenotype)\n",
    "WHERE phe.label IN [\n",
    "  \"Growth delay\", \n",
    "  \"Large knee\", \n",
    "  \"Sensorineural hearing impairment\", \n",
    "  \"Pruritus\", \n",
    "  \"Type I diabetes mellitus\"\n",
    "]\n",
    "WITH phe\n",
    "MATCH path=(dis:HpoDisease)-[:HAS_PHENOTYPIC_FEATURE]->(phe)\n",
    "UNWIND dis as nodes\n",
    "RETURN\n",
    "  dis.id as disease_id, \n",
    "  dis.label as disease_name,\n",
    "  collect(phe.label) as features,\n",
    "  count(nodes) as num_of_features\n",
    "ORDER BY num_of_features DESC, disease_name\n",
    "LIMIT 5\"\"\"\n",
    "\n",
    "# to see the  the symptoms of a disease\n",
    "\"\"\"MATCH path=(dis:HpoDisease)-[:HAS_PHENOTYPIC_FEATURE]->(phe:HpoPhenotype)\n",
    "WHERE dis.id = \"OMIM:222100\"\n",
    "RETURN path\"\"\"\n",
    "\n",
    "# see the subclasses of endocrine system for at most depth 3\n",
    "\"\"\"MATCH (p:HpoPhenotype)<-[:SUBCLASSOF*1..3]-(n:HpoPhenotype)  \n",
    "WHERE p.id = \"HP:0000818\"\n",
    "RETURN p,n\"\"\"\n",
    "\n",
    "\n",
    "#Subset of the results of annotations implicitly connected to the “Abnormality of the\n",
    "#endocrine system” phenotypic feature. Phenotypic features that are direct or inferred subclasses of this\n",
    "#phenotypic feature are highlighted in bold.\n",
    "\"\"\"MATCH (cat:HpoPhenotype {label: \"Abnormality of the endocrine system\"})  \n",
    "CALL n10s.inference.nodesInCategory(cat, { \n",
    "  inCatRel: \"HAS_PHENOTYPIC_FEATURE\", \n",
    "  subCatRel: \"SUBCLASSOF\"})  \n",
    "YIELD node as dis\n",
    "WHERE dis.label IN [\n",
    "  \"Congenital atransferrinemia\",\n",
    "  \"Deafness, autosomal recessive 4, with enlarged vestibular aqueduct\",\n",
    "  \"Diabetes mellitus, transient neonatal, 1\",\n",
    "  \"Edema, familial idiopathic, prepubertal\",\n",
    "  \"Familial dysalbuminemic hyperthyroxinemia\"\n",
    "]   \n",
    "MATCH (dis)-[:HAS_PHENOTYPIC_FEATURE]->(phe:HpoPhenotype)  \n",
    "RETURN dis.label as disease, collect(DISTINCT phe.label) as features\n",
    "ORDER BY size(features) ASC, disease\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_neo4j",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
