{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "eea77ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import logging\n",
    "from dotenv import load_dotenv\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "# Load credentials from .env\n",
    "load_dotenv()\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "class PrimeKGImporter:\n",
    "    def __init__(self):\n",
    "        self.uri = os.getenv(\"NEO4J_URI\")\n",
    "        self.auth = (os.getenv(\"NEO4J_USERNAME\"), os.getenv(\"NEO4J_PASSWORD\"))\n",
    "        self.driver = GraphDatabase.driver(self.uri, auth=self.auth)\n",
    "        self.driver.verify_connectivity()\n",
    "\n",
    "    def close(self):\n",
    "        self.driver.close()\n",
    "\n",
    "    def set_constraints(self):\n",
    "        # create a fast lookup indices for node index type and id to make the search faster\n",
    "        # create constraint on node index since it has to be unique.\n",
    "        queries = [\n",
    "            \"CREATE CONSTRAINT node_index_unique IF NOT EXISTS FOR (n:Entity) REQUIRE n.node_index IS UNIQUE\",\n",
    "            \"CREATE INDEX entity_type_idx IF NOT EXISTS FOR (n:Entity) ON (n.type)\",\n",
    "            \"CREATE INDEX entity_id_idx IF NOT EXISTS FOR (n:Entity) ON (n.id)\",\n",
    "            \"CREATE INDEX disease_index_node_index IF NOT EXISTS FOR (n:disease) ON (n.node_index)\"\n",
    "        ]\n",
    "        with self.driver.session() as session:\n",
    "            for q in queries:\n",
    "                session.run(q)\n",
    "        logging.info(\"Constraints on node_index and indexes established.\")\n",
    "\n",
    "    def import_nodes_by_type(self, nodes_csv_path, node_type):\n",
    "        \n",
    "        #Imports nodes and applies the node_type as a Neo4j Label using APOC.\n",
    "        #This allows to query specifically like MATCH (n:drug) or MATCH (n:disease).\n",
    "        # apoc.create.addLabels allows us to set the label dynamically from the CSV/parameter\n",
    "        query = \"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM $file_url AS row\n",
    "        WITH row WHERE row.node_type = $target_type\n",
    "        MERGE (n:Entity {node_index: toInteger(row.node_index)})\n",
    "        SET n.id = row.node_id,\n",
    "            n.type = row.node_type,\n",
    "            n.name = row.node_name,\n",
    "            n.source = row.node_source\n",
    "        WITH n, row\n",
    "        CALL apoc.create.addLabels(n, [row.node_type]) YIELD node\n",
    "        RETURN count(node)\n",
    "        \"\"\"\n",
    "        file_url = f\"file:///{os.path.basename(nodes_csv_path)}\"\n",
    "        with self.driver.session() as session:\n",
    "            session.run(query, file_url=file_url, target_type=node_type)\n",
    "        logging.info(f\"Nodes of type '{node_type}' imported and labeled.\")\n",
    "    def import_edges_by_type(self, edges_csv_path, relation_type):\n",
    "        query = f\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM $file_url AS row\n",
    "        WITH row WHERE row.relation = $rel_type\n",
    "        MATCH (source:Entity {{node_index: toInteger(row.x_index)}})\n",
    "        MATCH (target:Entity {{node_index: toInteger(row.y_index)}})\n",
    "        CALL apoc.create.relationship(source, row.relation, {{display: row.display_relation}}, target) YIELD rel\n",
    "        RETURN count(rel)\n",
    "        \"\"\"\n",
    "        file_url = f\"file:///{os.path.basename(edges_csv_path)}\"\n",
    "        with self.driver.session() as session:\n",
    "            result = session.run(query, file_url=file_url, rel_type=relation_type)\n",
    "            summary = result.consume()\n",
    "            logging.info(f\"Imported {relation_type} edges.\")\n",
    "\n",
    "    def enrich_drug_features(self, drug_features_csv):\n",
    "        \"\"\"\n",
    "        Enriches 'drug' nodes with 'mechanism_of_action' and 'description'.\n",
    "        \"\"\"\n",
    "        query = \"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM $file_url AS row\n",
    "        MATCH (n:drug {node_index: toInteger(row.node_index)})\n",
    "        SET n.mechanism_of_action = row.mechanism_of_action,\n",
    "            n.description = row.description\n",
    "        \"\"\"\n",
    "        file_url = f\"file:///{os.path.basename(drug_features_csv)}\"\n",
    "        with self.driver.session() as session:\n",
    "            session.run(query, file_url=file_url)\n",
    "        logging.info(\"Drug nodes enriched with mechanisms and descriptions.\")\n",
    "    def enrich_disease_features(self, disease_features_csv):\n",
    "        \"\"\"\n",
    "        Refined enrichment:\n",
    "        Uses group_name_bert -> mondo_name fallback for name.\n",
    "        Uses mondo_definition -> orphanet_definition fallback for text.\n",
    "        Merges all unique definitions found across duplicates.\n",
    "        \"\"\"\n",
    "\n",
    "        logging.info(f\"Reading {disease_features_csv}...\")\n",
    "        df = pd.read_csv(disease_features_csv)\n",
    "        \n",
    "        df['final_name'] = df['group_name_bert'].fillna(df['mondo_name'])\n",
    "        \n",
    "        df['temp_definition'] = df['mondo_definition'].fillna(df['orphanet_definition'])\n",
    "        \n",
    "        logging.info(\"Merging sub-types and multi-source definitions...\")\n",
    "        \n",
    "        # Aggregation\n",
    "        df_collapsed = df.groupby('node_index').agg({\n",
    "            'final_name': 'first',\n",
    "            'mondo_name': lambda x: \" | \".join(sorted(set(str(i) for i in x if pd.notnull(i)))),\n",
    "            'temp_definition': lambda x: \"\\n\\n\".join(set(str(i) for i in x if pd.notnull(i) and str(i).strip() != \"\")),\n",
    "            'mayo_symptoms': lambda x: \"\\n\\n\".join(set(str(i) for i in x if pd.notnull(i) and str(i).strip() != \"\"))\n",
    "        }).reset_index()\n",
    "\n",
    "        df_collapsed = df_collapsed.replace({np.nan: None, \"\": None})\n",
    "        total_unique = len(df_collapsed)\n",
    "        \n",
    "        query = \"\"\"\n",
    "        UNWIND $batch AS row\n",
    "        MATCH (n:disease {node_index: toInteger(row.node_index)})\n",
    "        SET n.name = row.final_name,\n",
    "            n.subtypes = row.mondo_name,\n",
    "            n.definition = row.temp_definition,\n",
    "            n.symptoms = row.mayo_symptoms\n",
    "        \"\"\"\n",
    "\n",
    "        batch_size = 2000 \n",
    "        \n",
    "        with self.driver.session() as session:\n",
    "            logging.info(f\"Starting batch update for {total_unique} unique nodes...\")\n",
    "\n",
    "            for start_idx in range(0, total_unique, batch_size):\n",
    "                end_idx = min(start_idx + batch_size, total_unique)\n",
    "                batch_df = df_collapsed.iloc[start_idx:end_idx]\n",
    "                batch_data = batch_df.to_dict('records')\n",
    "                \n",
    "                session.run(query, batch=batch_data)\n",
    "                \n",
    "                percent_done = (end_idx / total_unique) * 100\n",
    "                print(f\"Progress: {percent_done:.2f}% ({end_idx}/{total_unique} nodes enriched)\", end='\\r')\n",
    "\n",
    "            print(f\"\\nSuccess: {total_unique} disease nodes enriched.\")\n",
    "    def run_graph_analysis(self):        \n",
    "        analysis_query = \"\"\"\n",
    "        CALL {\n",
    "            MATCH (d:disease)\n",
    "            RETURN \n",
    "                count(d) AS total_diseases, \n",
    "                sum(CASE WHEN d.definition IS NULL OR d.definition = \"\" THEN 1 ELSE 0 END) AS null_definitions\n",
    "        }\n",
    "    \n",
    "        CALL {\n",
    "            MATCH (dr:drug)\n",
    "            RETURN \n",
    "                count(dr) AS total_drugs, \n",
    "                sum(CASE WHEN dr.mechanism_of_action IS NULL OR dr.mechanism_of_action = \"\" THEN 1 ELSE 0 END) AS null_mechanisms,\n",
    "                sum(CASE WHEN dr.description IS NULL OR dr.description = \"\" THEN 1 ELSE 0 END) AS null_descriptions\n",
    "\n",
    "        }\n",
    "        RETURN total_diseases, null_definitions, total_drugs, null_mechanisms,null_descriptions\n",
    "        \"\"\"\n",
    "\n",
    "        with self.driver.session() as session:\n",
    "            result = session.run(analysis_query).single()\n",
    "            \n",
    "            print(f\"--- Disease Analysis ---\")\n",
    "            print(f\"Total Diseases (x): {result['total_diseases']}\")\n",
    "            print(f\"Null Definitions (y): {result['null_definitions']}\")\n",
    "            \n",
    "            print(f\"\\n--- Drug Analysis ---\")\n",
    "            print(f\"Total Drugs (a): {result['total_drugs']}\")\n",
    "            print(f\"Null Mechanism of Action (b): {result['null_mechanisms']}\")\n",
    "            print(f\"Null Descriptions (c): {result['null_descriptions']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "048ceec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "importer = PrimeKGImporter()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7504dbc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-14 09:53:50,472 - INFO - Nodes of type 'drug' imported and labeled.\n"
     ]
    }
   ],
   "source": [
    "importer.import_nodes_by_type(\"nodes.csv\",\"drug\") # 7957 drug node "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cc7a4d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-14 09:53:53,206 - INFO - Nodes of type 'disease' imported and labeled.\n"
     ]
    }
   ],
   "source": [
    "importer.import_nodes_by_type(\"nodes.csv\",\"disease\") # 17080 disease node "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "57ba38bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-14 09:53:54,139 - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT node_index_unique IF NOT EXISTS FOR (e:Entity) REQUIRE (e.node_index) IS UNIQUE` has no effect.} {description: `CONSTRAINT node_index_unique FOR (e:Entity) REQUIRE (e.node_index) IS UNIQUE` already exists.} {position: None} for query: 'CREATE CONSTRAINT node_index_unique IF NOT EXISTS FOR (n:Entity) REQUIRE n.node_index IS UNIQUE'\n",
      "2026-02-14 09:53:54,151 - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE RANGE INDEX entity_type_idx IF NOT EXISTS FOR (e:Entity) ON (e.type)` has no effect.} {description: `RANGE INDEX index_3d7b3819 FOR (e:Entity) ON (e.type)` already exists.} {position: None} for query: 'CREATE INDEX entity_type_idx IF NOT EXISTS FOR (n:Entity) ON (n.type)'\n",
      "2026-02-14 09:53:54,159 - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE RANGE INDEX entity_id_idx IF NOT EXISTS FOR (e:Entity) ON (e.id)` has no effect.} {description: `RANGE INDEX entity_id_idx FOR (e:Entity) ON (e.id)` already exists.} {position: None} for query: 'CREATE INDEX entity_id_idx IF NOT EXISTS FOR (n:Entity) ON (n.id)'\n",
      "2026-02-14 09:53:54,166 - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE RANGE INDEX disease_index_node_index IF NOT EXISTS FOR (e:disease) ON (e.node_index)` has no effect.} {description: `RANGE INDEX disease_index_node_index FOR (e:disease) ON (e.node_index)` already exists.} {position: None} for query: 'CREATE INDEX disease_index_node_index IF NOT EXISTS FOR (n:disease) ON (n.node_index)'\n",
      "2026-02-14 09:53:54,168 - INFO - Constraints on node_index and indexes established.\n"
     ]
    }
   ],
   "source": [
    "importer.set_constraints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b963546a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-14 09:55:05,974 - INFO - Drug nodes enriched with mechanisms and descriptions.\n"
     ]
    }
   ],
   "source": [
    "importer.enrich_drug_features(\"drug_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0cc9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned file saved to import/disease_features_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "input_path=\"import/disease_features.csv\"\n",
    "output_path=\"import/disease_features_cleaned.csv\"\n",
    "df = pd.read_csv(input_path)\n",
    "\n",
    "# Clean common issues in text columns (mondo_definition, etc.)\n",
    "# Replace actual double quotes inside the text with single quotes \n",
    "# or escape them. Single quotes are safer for Neo4j LOAD CSV.\n",
    "text_columns = ['mondo_definition', 'mayo_symptoms', 'orphanet_definition']\n",
    "\n",
    "for col in text_columns:\n",
    "    if col in df.columns:\n",
    "        # Replace \" with ' to avoid breaking the CSV structure\n",
    "        df[col] = df[col].astype(str).str.replace('\"', \"'\", regex=False)\n",
    "\n",
    "# Export with explicit quoting rules\n",
    "df.to_csv(\n",
    "    output_path, \n",
    "    index=False, \n",
    "    quoting=csv.QUOTE_ALL, \n",
    "    quotechar='\"', \n",
    "    escapechar='\\\\' # Adds a backslash if it finds a stray quote\n",
    ")\n",
    "\n",
    "print(f\"Cleaned file saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c4ae8401",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-14 09:55:13,207 - INFO - Reading import/disease_features_cleaned.csv...\n",
      "2026-02-14 09:55:14,821 - INFO - Merging sub-types and multi-source definitions...\n",
      "2026-02-14 09:55:16,425 - INFO - Starting batch update for 17080 unique nodes...\n",
      "2026-02-14 09:55:16,440 - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE RANGE INDEX disease_node_idx IF NOT EXISTS FOR (e:disease) ON (e.node_index)` has no effect.} {description: `RANGE INDEX disease_index_node_index FOR (e:disease) ON (e.node_index)` already exists.} {position: None} for query: 'CREATE INDEX disease_node_idx IF NOT EXISTS FOR (n:disease) ON (n.node_index)'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 100.00% (17080/17080 nodes enriched)\n",
      "Success: 17080 disease nodes enriched.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "importer.enrich_disease_features(\"import/disease_features_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ec6f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows in CSV: 44133\n",
      "Unique node_index count: 17080\n",
      "\n",
      "Example of duplicated node_index in CSV:\n",
      "       node_index                      mondo_name  mondo_id  \\\n",
      "31059       27158  osteogenesis imperfecta type 1      8146   \n",
      "31048       27158  osteogenesis imperfecta type 5     12591   \n",
      "31049       27158  osteogenesis imperfecta type 5     12591   \n",
      "31050       27158  osteogenesis imperfecta type 5     12591   \n",
      "\n",
      "                                        mondo_definition  \\\n",
      "31059  Osteogenesis imperfecta type I is a mild type ...   \n",
      "31048  Osteogenesis imperfecta type V is a moderate t...   \n",
      "31049  Osteogenesis imperfecta type V is a moderate t...   \n",
      "31050  Osteogenesis imperfecta type V is a moderate t...   \n",
      "\n",
      "               group_name_bert  \n",
      "31059  osteogenesis imperfecta  \n",
      "31048  osteogenesis imperfecta  \n",
      "31049  osteogenesis imperfecta  \n",
      "31050  osteogenesis imperfecta  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_path=\"import/disease_features.csv\"\n",
    "\n",
    "df = pd.read_csv(input_path)\n",
    "\n",
    "print(f\"Total Rows in CSV: {len(df)}\")\n",
    "print(f\"Unique node_index count: {df['node_index'].nunique()}\")\n",
    "\n",
    "duplicates = df[df.duplicated(subset=['node_index'], keep=False)].sort_values('node_index')\n",
    "if not duplicates.empty:\n",
    "    print(\"\\nExample of duplicated node_index in CSV:\")\n",
    "    print(duplicates[['node_index', 'mondo_name', 'mondo_id',\"mondo_definition\",\"group_name_bert\"]].head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68afab11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of diseases with conflicting definitions: 881\n",
      "\n",
      "Example of conflicting names for one index:\n",
      "[array(['osteogenesis imperfecta type 13',\n",
      "        'osteogenesis imperfecta type 11',\n",
      "        'osteogenesis imperfecta type 17',\n",
      "        'osteogenesis imperfecta type 12',\n",
      "        'osteogenesis imperfecta type 5', 'osteogenesis imperfecta type 7',\n",
      "        'osteogenesis imperfecta, type 21',\n",
      "        'osteogenesis imperfecta type 1', 'osteogenesis imperfecta type 4',\n",
      "        'osteogenesis imperfecta, type 20',\n",
      "        'osteogenesis imperfecta type 10',\n",
      "        'osteogenesis imperfecta, type 18',\n",
      "        'osteogenesis imperfecta type 16',\n",
      "        'osteogenesis imperfecta type 9',\n",
      "        'osteogenesis imperfecta, type 19',\n",
      "        'osteogenesis imperfecta type 3',\n",
      "        'osteogenesis imperfecta type 15',\n",
      "        'osteogenesis imperfecta type 2', 'osteogenesis imperfecta type 6',\n",
      "        'osteogenesis imperfecta type 14',\n",
      "        'osteogenesis imperfecta type 8', 'osteogenesis imperfecta'],\n",
      "       dtype=object)                                                       ]\n"
     ]
    }
   ],
   "source": [
    "# Group by node_index and see how many unique definitions/symptoms each one has\n",
    "diff_check = df.groupby('node_index').agg({\n",
    "    'mondo_definition': 'nunique',\n",
    "    'mayo_symptoms': 'nunique',\n",
    "    'mondo_name': 'unique'\n",
    "})\n",
    "\n",
    "# Filter for nodes that have more than one unique definition\n",
    "conflicts = diff_check[diff_check['mondo_definition'] > 1]\n",
    "\n",
    "print(f\"Number of diseases with conflicting definitions: {len(conflicts)}\")\n",
    "if not conflicts.empty:\n",
    "    print(\"\\nExample of conflicting names for one index:\")\n",
    "    print(conflicts['mondo_name'].head(1).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "83c4facc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-14 10:17:39,734 - WARNING - Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL () { ... }} {position: line: 2, column: 9, offset: 9} for query: '\\n        CALL {\\n            MATCH (d:disease)\\n            RETURN \\n                count(d) AS total_diseases, \\n                sum(CASE WHEN d.definition IS NULL OR d.definition = \"\" THEN 1 ELSE 0 END) AS null_definitions\\n        }\\n\\n        CALL {\\n            MATCH (dr:drug)\\n            RETURN \\n                count(dr) AS total_drugs, \\n                sum(CASE WHEN dr.mechanism_of_action IS NULL OR dr.mechanism_of_action = \"\" THEN 1 ELSE 0 END) AS null_mechanisms,\\n                sum(CASE WHEN dr.description IS NULL OR dr.description = \"\" THEN 1 ELSE 0 END) AS null_descriptions\\n\\n        }\\n        RETURN total_diseases, null_definitions, total_drugs, null_mechanisms,null_descriptions\\n        '\n",
      "2026-02-14 10:17:39,735 - WARNING - Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL () { ... }} {position: line: 9, column: 9, offset: 241} for query: '\\n        CALL {\\n            MATCH (d:disease)\\n            RETURN \\n                count(d) AS total_diseases, \\n                sum(CASE WHEN d.definition IS NULL OR d.definition = \"\" THEN 1 ELSE 0 END) AS null_definitions\\n        }\\n\\n        CALL {\\n            MATCH (dr:drug)\\n            RETURN \\n                count(dr) AS total_drugs, \\n                sum(CASE WHEN dr.mechanism_of_action IS NULL OR dr.mechanism_of_action = \"\" THEN 1 ELSE 0 END) AS null_mechanisms,\\n                sum(CASE WHEN dr.description IS NULL OR dr.description = \"\" THEN 1 ELSE 0 END) AS null_descriptions\\n\\n        }\\n        RETURN total_diseases, null_definitions, total_drugs, null_mechanisms,null_descriptions\\n        '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Disease Analysis ---\n",
      "Total Diseases (x): 17080\n",
      "Null Definitions (y): 4182\n",
      "\n",
      "--- Drug Analysis ---\n",
      "Total Drugs (a): 7957\n",
      "Null Mechanism of Action (b): 4715\n",
      "Null Descriptions (c): 3366\n"
     ]
    }
   ],
   "source": [
    "importer.run_graph_analysis()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_neo4j",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
