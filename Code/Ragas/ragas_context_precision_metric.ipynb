{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f1716cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import List\n",
    "from ragas.metrics.collections import ContextPrecision\n",
    "from openai import AsyncOpenAI\n",
    "from typing import List\n",
    "from ragas import EvaluationDataset, experiment\n",
    "from ragas.llms import llm_factory\n",
    "from ragas.backends import LocalCSVBackend\n",
    "from ragas.metrics.collections import ContextPrecision\n",
    "from ragas.metrics.result import MetricResult\n",
    "from ragas_utils import DetailedMetricResult\n",
    "from ragas.metrics.collections.context_precision.util import (\n",
    "    ContextPrecisionInput, \n",
    "    ContextPrecisionOutput\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e927cffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TraceableContextPrecision(ContextPrecision):\n",
    "     async def ascore(\n",
    "        self, user_input: str, reference: str, retrieved_contexts: List[str]\n",
    "    ) -> DetailedMetricResult:\n",
    "        \"\"\"\n",
    "        Calculate context precision score using reference.\n",
    "\n",
    "        Args:\n",
    "            user_input: The question being asked\n",
    "            reference: The reference answer to compare against\n",
    "            retrieved_contexts: The retrieved contexts to evaluate\n",
    "\n",
    "        Returns:\n",
    "            MetricResult with context precision score (0.0-1.0, higher is better)\n",
    "        \"\"\"\n",
    "        # Input validation\n",
    "        if not user_input:\n",
    "            raise ValueError(\"user_input cannot be empty\")\n",
    "        if not reference:\n",
    "            raise ValueError(\"reference cannot be empty\")\n",
    "        if not retrieved_contexts:\n",
    "            raise ValueError(\"retrieved_contexts cannot be empty\")\n",
    "\n",
    "        # Evaluate each retrieved context\n",
    "        verdicts = []\n",
    "        reasons=[]\n",
    "        for context in retrieved_contexts:\n",
    "            # Create input data and generate prompt\n",
    "            input_data = ContextPrecisionInput(\n",
    "                question=user_input, context=context, answer=reference\n",
    "            )\n",
    "            prompt_string = self.prompt.to_string(input_data)\n",
    "            print(\"prompt\",prompt_string)\n",
    "            result = await self.llm.agenerate(prompt_string, ContextPrecisionOutput)\n",
    "            print(\"result\",result)\n",
    "            verdicts.append(result.verdict)\n",
    "            reasons.append(result.reason)\n",
    "\n",
    "        # Calculate average precision\n",
    "        score = self._calculate_average_precision(verdicts)\n",
    "        return DetailedMetricResult(\n",
    "            value=float(score),\n",
    "            reason=\", \".join([r for r in reasons]),\n",
    "            traces={\n",
    "                \"input\": {\"contexts\": [context for context in  retrieved_contexts]},\n",
    "                \"output\": {\"verdicts\": [v for v in verdicts]}\n",
    "            }\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bfc0de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AsyncOpenAI(base_url=\"http://localhost:11434/v1\", api_key=\"ollama\")\n",
    "llm = llm_factory(\"qwen2.5:3b\", provider=\"openai\", client=client)\n",
    "\n",
    "context_precision_metric = TraceableContextPrecision(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28c0f592",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [\n",
    "    {\n",
    "        \"user_input\": \"What is the capital of France?\",\n",
    "        \"reference\": \"The capital of France is Paris.\",\n",
    "        \"retrieved_contexts\": [\n",
    "            \"Paris is the capital and largest city of France.\", # Relevant\n",
    "            \"Marseille is a city in southern France.\",          # Irrelevant\n",
    "            \"Lyon is known for its cuisine.\"                   # Irrelevant\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "dataset = EvaluationDataset.from_pandas(pd.DataFrame(samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53140ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running experiment:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt Given question, answer and context verify if the context was useful in arriving at the given answer. Give verdict as \"1\" if useful and \"0\" if not with json output.\n",
      "Please return the output in a JSON format that complies with the following schema as specified in JSON Schema:\n",
      "{\"description\": \"Structured output for context precision evaluation.\", \"properties\": {\"reason\": {\"description\": \"Reason for verification\", \"title\": \"Reason\", \"type\": \"string\"}, \"verdict\": {\"description\": \"Binary (0/1) verdict of verification\", \"title\": \"Verdict\", \"type\": \"integer\"}}, \"required\": [\"reason\", \"verdict\"], \"title\": \"ContextPrecisionOutput\", \"type\": \"object\"}Do not use single quotes in your response but double quotes,properly escaped with a backslash.\n",
      "\n",
      "--------EXAMPLES-----------\n",
      "Example 1\n",
      "Input: {\n",
      "    \"question\": \"What can you tell me about Albert Einstein?\",\n",
      "    \"context\": \"Albert Einstein (14 March 1879 – 18 April 1955) was a German-born theoretical physicist, widely held to be one of the greatest and most influential scientists of all time. Best known for developing the theory of relativity, he also made important contributions to quantum mechanics, and was thus a central figure in the revolutionary reshaping of the scientific understanding of nature that modern physics accomplished in the first decades of the twentieth century. His mass–energy equivalence formula E = mc2, which arises from relativity theory, has been called 'the world's most famous equation'. He received the 1921 Nobel Prize in Physics 'for his services to theoretical physics, and especially for his discovery of the law of the photoelectric effect', a pivotal step in the development of quantum theory. His work is also known for its influence on the philosophy of science. In a 1999 poll of 130 leading physicists worldwide by the British journal Physics World, Einstein was ranked the greatest physicist of all time. His intellectual achievements and originality have made Einstein synonymous with genius.\",\n",
      "    \"answer\": \"Albert Einstein, born on 14 March 1879, was a German-born theoretical physicist, widely held to be one of the greatest and most influential scientists of all time. He received the 1921 Nobel Prize in Physics for his services to theoretical physics.\"\n",
      "}\n",
      "Output: {\n",
      "    \"reason\": \"The provided context was indeed useful in arriving at the given answer. The context includes key information about Albert Einstein's life and contributions, which are reflected in the answer.\",\n",
      "    \"verdict\": 1\n",
      "}\n",
      "\n",
      "Example 2\n",
      "Input: {\n",
      "    \"question\": \"who won 2020 icc world cup?\",\n",
      "    \"context\": \"The 2022 ICC Men's T20 World Cup, held from October 16 to November 13, 2022, in Australia, was the eighth edition of the tournament. Originally scheduled for 2020, it was postponed due to the COVID-19 pandemic. England emerged victorious, defeating Pakistan by five wickets in the final to clinch their second ICC Men's T20 World Cup title.\",\n",
      "    \"answer\": \"England\"\n",
      "}\n",
      "Output: {\n",
      "    \"reason\": \"the context was useful in clarifying the situation regarding the 2020 ICC World Cup and indicating that England was the winner of the tournament that was intended to be held in 2020 but actually took place in 2022.\",\n",
      "    \"verdict\": 1\n",
      "}\n",
      "\n",
      "Example 3\n",
      "Input: {\n",
      "    \"question\": \"What is the tallest mountain in the world?\",\n",
      "    \"context\": \"The Andes is the longest continental mountain range in the world, located in South America. It stretches across seven countries and features many of the highest peaks in the Western Hemisphere. The range is known for its diverse ecosystems, including the high-altitude Andean Plateau and the Amazon rainforest.\",\n",
      "    \"answer\": \"Mount Everest.\"\n",
      "}\n",
      "Output: {\n",
      "    \"reason\": \"the provided context discusses the Andes mountain range, which, while impressive, does not include Mount Everest or directly relate to the question about the world's tallest mountain.\",\n",
      "    \"verdict\": 0\n",
      "}\n",
      "-----------------------------\n",
      "\n",
      "Now perform the same with the following input\n",
      "input: {\n",
      "    \"question\": \"What is the capital of France?\",\n",
      "    \"context\": \"Paris is the capital and largest city of France.\",\n",
      "    \"answer\": \"The capital of France is Paris.\"\n",
      "}\n",
      "Output: \n",
      "result reason='the context provided directly states that Paris is the capital of France, which matches exactly with the given answer.' verdict=1\n",
      "prompt Given question, answer and context verify if the context was useful in arriving at the given answer. Give verdict as \"1\" if useful and \"0\" if not with json output.\n",
      "Please return the output in a JSON format that complies with the following schema as specified in JSON Schema:\n",
      "{\"description\": \"Structured output for context precision evaluation.\", \"properties\": {\"reason\": {\"description\": \"Reason for verification\", \"title\": \"Reason\", \"type\": \"string\"}, \"verdict\": {\"description\": \"Binary (0/1) verdict of verification\", \"title\": \"Verdict\", \"type\": \"integer\"}}, \"required\": [\"reason\", \"verdict\"], \"title\": \"ContextPrecisionOutput\", \"type\": \"object\"}Do not use single quotes in your response but double quotes,properly escaped with a backslash.\n",
      "\n",
      "--------EXAMPLES-----------\n",
      "Example 1\n",
      "Input: {\n",
      "    \"question\": \"What can you tell me about Albert Einstein?\",\n",
      "    \"context\": \"Albert Einstein (14 March 1879 – 18 April 1955) was a German-born theoretical physicist, widely held to be one of the greatest and most influential scientists of all time. Best known for developing the theory of relativity, he also made important contributions to quantum mechanics, and was thus a central figure in the revolutionary reshaping of the scientific understanding of nature that modern physics accomplished in the first decades of the twentieth century. His mass–energy equivalence formula E = mc2, which arises from relativity theory, has been called 'the world's most famous equation'. He received the 1921 Nobel Prize in Physics 'for his services to theoretical physics, and especially for his discovery of the law of the photoelectric effect', a pivotal step in the development of quantum theory. His work is also known for its influence on the philosophy of science. In a 1999 poll of 130 leading physicists worldwide by the British journal Physics World, Einstein was ranked the greatest physicist of all time. His intellectual achievements and originality have made Einstein synonymous with genius.\",\n",
      "    \"answer\": \"Albert Einstein, born on 14 March 1879, was a German-born theoretical physicist, widely held to be one of the greatest and most influential scientists of all time. He received the 1921 Nobel Prize in Physics for his services to theoretical physics.\"\n",
      "}\n",
      "Output: {\n",
      "    \"reason\": \"The provided context was indeed useful in arriving at the given answer. The context includes key information about Albert Einstein's life and contributions, which are reflected in the answer.\",\n",
      "    \"verdict\": 1\n",
      "}\n",
      "\n",
      "Example 2\n",
      "Input: {\n",
      "    \"question\": \"who won 2020 icc world cup?\",\n",
      "    \"context\": \"The 2022 ICC Men's T20 World Cup, held from October 16 to November 13, 2022, in Australia, was the eighth edition of the tournament. Originally scheduled for 2020, it was postponed due to the COVID-19 pandemic. England emerged victorious, defeating Pakistan by five wickets in the final to clinch their second ICC Men's T20 World Cup title.\",\n",
      "    \"answer\": \"England\"\n",
      "}\n",
      "Output: {\n",
      "    \"reason\": \"the context was useful in clarifying the situation regarding the 2020 ICC World Cup and indicating that England was the winner of the tournament that was intended to be held in 2020 but actually took place in 2022.\",\n",
      "    \"verdict\": 1\n",
      "}\n",
      "\n",
      "Example 3\n",
      "Input: {\n",
      "    \"question\": \"What is the tallest mountain in the world?\",\n",
      "    \"context\": \"The Andes is the longest continental mountain range in the world, located in South America. It stretches across seven countries and features many of the highest peaks in the Western Hemisphere. The range is known for its diverse ecosystems, including the high-altitude Andean Plateau and the Amazon rainforest.\",\n",
      "    \"answer\": \"Mount Everest.\"\n",
      "}\n",
      "Output: {\n",
      "    \"reason\": \"the provided context discusses the Andes mountain range, which, while impressive, does not include Mount Everest or directly relate to the question about the world's tallest mountain.\",\n",
      "    \"verdict\": 0\n",
      "}\n",
      "-----------------------------\n",
      "\n",
      "Now perform the same with the following input\n",
      "input: {\n",
      "    \"question\": \"What is the capital of France?\",\n",
      "    \"context\": \"Marseille is a city in southern France.\",\n",
      "    \"answer\": \"The capital of France is Paris.\"\n",
      "}\n",
      "Output: \n",
      "result reason='The provided context about Marseille does not provide any information relevant to determining the capital of France. The answer given, however, correctly states that Paris is the capital of France.' verdict=0\n",
      "prompt Given question, answer and context verify if the context was useful in arriving at the given answer. Give verdict as \"1\" if useful and \"0\" if not with json output.\n",
      "Please return the output in a JSON format that complies with the following schema as specified in JSON Schema:\n",
      "{\"description\": \"Structured output for context precision evaluation.\", \"properties\": {\"reason\": {\"description\": \"Reason for verification\", \"title\": \"Reason\", \"type\": \"string\"}, \"verdict\": {\"description\": \"Binary (0/1) verdict of verification\", \"title\": \"Verdict\", \"type\": \"integer\"}}, \"required\": [\"reason\", \"verdict\"], \"title\": \"ContextPrecisionOutput\", \"type\": \"object\"}Do not use single quotes in your response but double quotes,properly escaped with a backslash.\n",
      "\n",
      "--------EXAMPLES-----------\n",
      "Example 1\n",
      "Input: {\n",
      "    \"question\": \"What can you tell me about Albert Einstein?\",\n",
      "    \"context\": \"Albert Einstein (14 March 1879 – 18 April 1955) was a German-born theoretical physicist, widely held to be one of the greatest and most influential scientists of all time. Best known for developing the theory of relativity, he also made important contributions to quantum mechanics, and was thus a central figure in the revolutionary reshaping of the scientific understanding of nature that modern physics accomplished in the first decades of the twentieth century. His mass–energy equivalence formula E = mc2, which arises from relativity theory, has been called 'the world's most famous equation'. He received the 1921 Nobel Prize in Physics 'for his services to theoretical physics, and especially for his discovery of the law of the photoelectric effect', a pivotal step in the development of quantum theory. His work is also known for its influence on the philosophy of science. In a 1999 poll of 130 leading physicists worldwide by the British journal Physics World, Einstein was ranked the greatest physicist of all time. His intellectual achievements and originality have made Einstein synonymous with genius.\",\n",
      "    \"answer\": \"Albert Einstein, born on 14 March 1879, was a German-born theoretical physicist, widely held to be one of the greatest and most influential scientists of all time. He received the 1921 Nobel Prize in Physics for his services to theoretical physics.\"\n",
      "}\n",
      "Output: {\n",
      "    \"reason\": \"The provided context was indeed useful in arriving at the given answer. The context includes key information about Albert Einstein's life and contributions, which are reflected in the answer.\",\n",
      "    \"verdict\": 1\n",
      "}\n",
      "\n",
      "Example 2\n",
      "Input: {\n",
      "    \"question\": \"who won 2020 icc world cup?\",\n",
      "    \"context\": \"The 2022 ICC Men's T20 World Cup, held from October 16 to November 13, 2022, in Australia, was the eighth edition of the tournament. Originally scheduled for 2020, it was postponed due to the COVID-19 pandemic. England emerged victorious, defeating Pakistan by five wickets in the final to clinch their second ICC Men's T20 World Cup title.\",\n",
      "    \"answer\": \"England\"\n",
      "}\n",
      "Output: {\n",
      "    \"reason\": \"the context was useful in clarifying the situation regarding the 2020 ICC World Cup and indicating that England was the winner of the tournament that was intended to be held in 2020 but actually took place in 2022.\",\n",
      "    \"verdict\": 1\n",
      "}\n",
      "\n",
      "Example 3\n",
      "Input: {\n",
      "    \"question\": \"What is the tallest mountain in the world?\",\n",
      "    \"context\": \"The Andes is the longest continental mountain range in the world, located in South America. It stretches across seven countries and features many of the highest peaks in the Western Hemisphere. The range is known for its diverse ecosystems, including the high-altitude Andean Plateau and the Amazon rainforest.\",\n",
      "    \"answer\": \"Mount Everest.\"\n",
      "}\n",
      "Output: {\n",
      "    \"reason\": \"the provided context discusses the Andes mountain range, which, while impressive, does not include Mount Everest or directly relate to the question about the world's tallest mountain.\",\n",
      "    \"verdict\": 0\n",
      "}\n",
      "-----------------------------\n",
      "\n",
      "Now perform the same with the following input\n",
      "input: {\n",
      "    \"question\": \"What is the capital of France?\",\n",
      "    \"context\": \"Lyon is known for its cuisine.\",\n",
      "    \"answer\": \"The capital of France is Paris.\"\n",
      "}\n",
      "Output: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running experiment: 100%|██████████| 1/1 [00:21<00:00, 21.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result reason=\"The provided context about Lyon and its cuisine does not provide any information relevant to determining the capital of France. The answer given ('Paris') aligns with common knowledge, but the context does not support this claim.\" verdict=0\n",
      "                       user_input  \\\n",
      "0  What is the capital of France?   \n",
      "\n",
      "                                            contexts  context_precision_score  \\\n",
      "0  [Paris is the capital and largest city of Fran...                      1.0   \n",
      "\n",
      "                                           reasoning   verdicts  \n",
      "0  the context provided directly states that Pari...  [1, 0, 0]  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "@experiment(\n",
    "    name_prefix=\"ragas_context_precision_test_\",\n",
    "    backend=LocalCSVBackend(root_dir=\".\")\n",
    ")\n",
    "async def run_evaluation(row):   \n",
    "    cp_result = await context_precision_metric.ascore(\n",
    "        user_input=row.user_input,\n",
    "        reference=row.reference,\n",
    "        retrieved_contexts=row.retrieved_contexts\n",
    "    )\n",
    "    return {\n",
    "        \"user_input\": row.user_input,\n",
    "        \"contexts\": row.retrieved_contexts,\n",
    "        \"context_precision_score\": cp_result.value,\n",
    "        \"reasoning\": cp_result.reason,\n",
    "        \"verdicts\": str(cp_result.traces[\"output\"][\"verdicts\"])\n",
    "    }\n",
    "\n",
    "results = await run_evaluation.arun(dataset=dataset)\n",
    "print(results.to_pandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d0069e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
